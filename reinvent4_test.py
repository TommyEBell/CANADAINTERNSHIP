# -*- coding: utf-8 -*-
"""REINVENT4_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R6S9UAwzwgFTIE-quYGmYLeChrK3FOwV
"""

!git clone https://github.com/MolecularAI/REINVENT4.git

# Install Conda on Google Colab - THIS BIT NO LONGER REQUIRED
!pip install -q condacolab
import condacolab
condacolab.install()

# Create a new Conda environment named 'reinvent4' with Python 3.10
!conda create --name reinvent4 python=3.10 -y

# Activate the 'reinvent4' environment
!conda init bash
!source activate reinvent4

!conda env list

# Commented out IPython magic to ensure Python compatibility.
# %cd REINVENT4/

!pip install -r requirements-linux-64.lock

pip install --no-deps .

!reinvent --help

# Install Miniconda
!wget -qO- https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh > miniconda.sh
!bash miniconda.sh -b -p /usr/local/miniconda

# Update PATH environment variable to include conda
import os
os.environ['PATH'] = '/usr/local/miniconda/bin:' + os.environ['PATH']

# Verify conda installation
!conda --version

# Install AutoDock Vina
!conda install -c bioconda autodock-vina -y

# Verify AutoDock Vina installation
!vina --version

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/MolecularAI/DockStream.git
# %cd /content/DockStream/
!pip install .

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/DockStream

!conda env create -f environment.yml
!conda init bash
!source activate DockStream

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

!git clone https://github.com/ccsb-scripps/AutoDock-Vina

"""END OF NECESSARY CODE"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/REINVENT4/

!reinvent /content/REINVENT4/configs/toml/sampling.toml # from cloned one

from google.colab import drive
drive.mount('/content/drive') # mount to one drive

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab_Notebooks/REINVENT4-main

!reinvent /content/drive/MyDrive/Colab_Notebooks/REINVENT4-main/configs/toml/sampling.toml # from drive one

"""TRYING TO REPRODUCE DATA"""

import os
import json
import tempfile

# update these paths to reflect your system's configuration
dockstream_path = os.path.expanduser("/content/DockStream")
dockstream_env = os.path.expanduser("/usr/local/miniconda/envs/DockStream")
vina_binary_location = os.path.expanduser("/usr/local/miniconda/bin/")

# no changes are necessary beyond this point
# ---------
# get the notebook's root path
try: ipynb_path
except NameError: ipynb_path = os.getcwd()

# generate the paths to the entry points
target_preparator = dockstream_path + "/target_preparator.py"
docker = dockstream_path + "/docker.py"

# generate a folder to store the results
output_dir = os.path.expanduser("/content")
try:
    os.mkdir(output_dir)
except FileExistsError:
    pass

# generate the paths to the files shipped with this implementation
apo_1UYD_path = "/content/drive/MyDrive/Colab_Notebooks/DockStream-master/case_study_files/2xch_apo.pdb"
reference_ligand_path = "/content/drive/MyDrive/Colab_Notebooks/DockStream-master/case_study_files/2xch_ligand.pdb"
smiles_path = "/content/drive/MyDrive/Colab_Notebooks/DockStream-master/case_study_files/reinvent_smiles.txt"

# generate output paths for the configuration file, the "fixed" PDB file and the "Gold" receptor
target_prep_path = output_dir + "/ADV_target_prep.json"
fixed_pdb_path = output_dir + "/ADV_fixed_target.pdb"
adv_receptor_path = output_dir + "/ADV_receptor.pdbqt"
log_file_target_prep = output_dir + "/ADV_target_prep.log"
log_file_docking = output_dir + "/ADV_docking.log"

# generate output paths for the configuration file, embedded ligands, the docked ligands and the scores
docking_path = output_dir + "/ADV_docking.json"
ligands_conformers_path = output_dir + "/ADV_embedded_ligands.sdf"
ligands_docked_path = output_dir + "/ADV_ligands_docked.sdf"
ligands_scores_path = output_dir + "/ADV_scores.csv"

# specify the target preparation JSON file as a dictionary and write it out
tp_dict = {
  "target_preparation":
  {
    "header": {                                   # general settings
      "logging": {                                # logging settings (e.g. which file to write to)
        "logfile": log_file_target_prep
      }
    },
    "input_path": apo_1UYD_path,                  # this should be an absolute path
    "fixer": {                                    # based on "PDBFixer"; tries to fix common problems with PDB files
      "enabled": True,
      "standardize": True,                        # enables standardization of residues
      "remove_heterogens": True,                  # remove hetero-entries
      "fix_missing_heavy_atoms": True,            # if possible, fix missing heavy atoms
      "fix_missing_hydrogens": True,              # add hydrogens, which are usually not present in PDB files
      "fix_missing_loops": False,                 # add missing loops; CAUTION: the result is usually not sufficient
      "add_water_box": False,                     # if you want to put the receptor into a box of water molecules
      "fixed_pdb_path": fixed_pdb_path            # if specified and not "None", the fixed PDB file will be stored here
    },
    "runs": [                                     # "runs" holds a list of backend runs; at least one is required
      {
        "backend": "AutoDockVina",                # one of the backends supported ("AutoDockVina", "OpenEye", ...)
        "output": {
          "receptor_path": adv_receptor_path      # the generated receptor file will be saved to this location
        },
        "parameters": {
          "pH": 7.4,                              # sets the protonation states (NOT used in Vina)
          "extract_box": {                        # in order to extract the coordinates of the pocket (see text)
            "reference_ligand_path": reference_ligand_path,   # path to the reference ligand
            "reference_ligand_format": "PDB"                  # format of the reference ligand
          }
}}]}}

with open(target_prep_path, 'w') as f:
    json.dump(tp_dict, f, indent="    ")

# execute this in a command-line environment after replacing the parameters
!{dockstream_env}/bin/python {target_preparator} -conf {target_prep_path}
!head -n 25 {adv_receptor_path}

# specify the embedding and docking JSON file as a dictionary and write it out
ed_dict = {
  "docking": {
    "header": {                                         # general settings
      "logging": {                                      # logging settings (e.g. which file to write to)
        "logfile": log_file_docking
      }
    },
    "ligand_preparation": {                             # the ligand preparation part, defines how to build the pool
      "embedding_pools": [
        {
          "pool_id": "RDkit_pool",                     # here, we only have one pool
          "type": "RDkit",
          "input": {
            "standardize_smiles": False,

          },
        }
      ]
    },
    "docking_runs": [
    {
      "backend": "AutoDockVina",
      "run_id": "AutoDockVina",
      "input_pools": ["RDkit_pool"],
      "parameters": {
        "binary_location": vina_binary_location,        # absolute path to the folder, where the "vina" binary
                                                        # can be found
        "parallelization": {
          "number_cores": 2
        },
        "seed": 42,                                     # use this "seed" to generate reproducible results; if
                                                        # varied, slightly different results will be produced
        "receptor_pdbqt_path": [adv_receptor_path],     # paths to the receptor files
        "number_poses": 2,                              # number of poses to be generated
        "search_space": {                               # search space (cavity definition); see text
          "--center_x": -39.7,
          "--center_y": 17,
          "--center_z": 12.6,
          "--size_x": 15,
          "--size_y": 10,
          "--size_z": 10
        }
      },
      "output": {
        "poses": { "poses_path": ligands_docked_path, "overwrite": False },
        "scores": { "scores_path": ligands_scores_path, "overwrite": False }
}}]}}

with open(docking_path, 'w') as f:
    json.dump(ed_dict, f, indent=2)

# initialize the dictionary
configuration = {
    "version": 3,# we are going to use REINVENT's newest release
    "run_type": "reinforcement_learning",  # other run types: "sampling", "validation",
                                           #                  "transfer_learning",
                                           #                  "scoring" and "create_model"
    "model_type": "default"
}

# add block to specify whether to run locally or not and
# where to store the results and logging
configuration["logging"] = {
    "sender": "http://0.0.0.1",            # only relevant if "recipient" is set to "remote"
    "recipient": "local",                  # either to local logging or use a remote REST-interface
    "logging_frequency": 1,                # log every x-th steps
    "logging_path": os.path.join(output_dir, "progress.log"), # load this folder in tensorboard
    "result_folder": os.path.join(output_dir, "results"),         # will hold the compounds (SMILES) and summaries
    "job_name": "Reinforcement learning DockStream demo",         # set an arbitrary job name for identification
    "job_id": "demo"                       # only relevant if "recipient" is set to a specific REST endpoint
}

# add the "parameters" block
configuration["parameters"] = {}

# add a "diversity_filter"
configuration["parameters"]["diversity_filter"] =  {
    "name": "IdenticalMurckoScaffold",     # other options are: "IdenticalTopologicalScaffold",
                                           #                    "NoFilter" and "ScaffoldSimilarity"
                                           # -> use "NoFilter" to disable this feature
    "nbmax": 25,                           # the bin size; penalization will start once this is exceeded
    "minscore": 0.4,                       # the minimum total score to be considered for binning
    "minsimilarity": 0.4                   # the minimum similarity to be placed into the same bin
}

# prepare the inception (we do not use it in this example, so "smiles" is an empty list)
configuration["parameters"]["inception"] = {
    "smiles": [],                          # fill in a list of SMILES here that can be used (or leave empty)
    "memory_size": 100,                    # sets how many molecules are to be remembered
    "sample_size": 10                      # how many are to be sampled each epoch from the memory
}

# set all "reinforcement learning"-specific run parameters
configuration["parameters"]["reinforcement_learning"] = {
    "prior": os.path.join(ipynb_path, "models/random.prior.new"), # path to the pre-trained model
    "agent": os.path.join(ipynb_path, "models/random.prior.new"), # path to the pre-trained model
    "n_steps": 2,                          # the number of epochs (steps) to be performed; often 1000
                                           # (set to 2 in this notebook to decrease docking computation time -
                                           # it is not expected that the agent will appreciably learn to
                                           # generate compounds with good docking scores in only 2 epochs.
                                           # The purpose of this notebook is to illustrate how DockStream
                                           # can be specified as a component to the `Scoring Function`)

    "sigma": 128,                          # used to calculate the "augmented likelihood", see publication
    "learning_rate": 0.0001,               # sets how strongly the agent is influenced by each epoch
    "batch_size": 8,                      # specifies how many molecules are generated per epoch, often 128
                                           # docking becomes more computationally demanding the greater the
                                           # batch size, as each compound must be docked. Depending on the
                                           # docking configuration, embedding ligands may generate different
                                           # tautomers, ionization states, etc., which will increase the number
                                           # of compounds that need to be docked. Batch size is set to 8 in
                                           # this notebook to decrease docking computation time and just
                                           # for illustration)
    "margin_threshold": 50                 # specify the (positive) margin between agent and prior
}

# prepare the scoring function definition and add at the end
scoring_function = {
    "name": "custom_product",                  # this is our default one (alternative: "custom_sum")
    "parallel": False,                         # sets whether components are to be executed
                                               # in parallel; note, that python uses "False" / "True"
                                               # but the JSON "false" / "true"

    # the "parameters" list holds the individual components
    "parameters": [

    # add component: use
    {
    "component_type": "dockstream",                           # use DockStream as a Scoring Function component
    "name": "Glide LigPrep Docking",                          # arbitrary name
    "weight": 1,
    "specific_parameters": {
        "transformation": {
            "transformation_type": "reverse_sigmoid",         # lower Glide scores are better - use reverse
                                                              # sigmoid transformation
            "low": -11,
            "high": -5,
            "k": 0.25
            },
        "configuration_path": docking_configuration_path,
        "docker_script_path": docker_path,
        "environment_path": dockstream_env
        }
    }]
}
configuration["parameters"]["scoring_function"] = scoring_function

# write the configuration file to the disc
configuration_JSON_path = os.path.join(output_dir, "RL_DockStream_config.json")
with open(configuration_JSON_path, 'w') as f:
    json.dump(configuration, f, indent=4, sort_keys=True)

!reinvent /content/drive/MyDrive/Colab_Notebooks/REINVENT4-main/case_study_files/TL_input_for_upload.toml

!reinvent /content/drive/MyDrive/Colab_Notebooks/REINVENT4-main/case_study_files/RL_direct_for_upload.toml

# Move only the files from the /content directory to /content/drive/MyDrive/Colab_Notebooks
!find /content/ -maxdepth 1 -type f -exec mv {} /content/drive/MyDrive/Colab_Notebooks \;